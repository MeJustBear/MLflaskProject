# Модель классификации новостей по категориям

## API
### Перед началом
#### UPD
Сейчас файлы модели доступны только на google drive.
Поскольку в проекте используются файлы, сильно превышающие размер в 200МБ, на хосте обязательно должен быть установлен [git lfs](https://git-lfs.github.com/).

### Сборка
Клонируем репозиторий, собираем образ с помощью compose.

```
$ git lfs clone https://github.com/MeJustBear/ml-flask-test-task
$ cd cd ml-flask-test-task/
$ docker-compose up
```

### Запуск

```
 $ docker run --name my-container -d -p 8080:8080 ml-flask-test-task
```

Если ничего не менялось в файле app/config.py, то контейнер запустится на [http://localhost:8000](http://localhost:8000)

### Функции внутри
Для обращения к функциям классификации, используются POST- и GET-запросы, где в параметрах передаются необходимые данные.

classify_url будет вызвана при обращении к URL: /predictByUrl с помощью POST- или GET-запрса с параметром 'analyseURL'. Вернёт .json-файл, с названиями категорий и вероятностью, с которой текст относится к каждой из них. В случае неправильного обращения(некорректного имени параметра), будет возвращён пустой json.
```
@application.route('/predictByUrl', methods=['GET', 'POST'])
def classify_url():  # put application's code here
    data = request.form
    if data:
        data = data['analyseURL']
        if data:
            values = mp.predict_by_url()
            return jsonify(values)
        if data:
            return jsonify({})    
    else:
        return jsonify({})
```
classify_text будет вызвана при обращении к URL: /predictByUrl с помощью POST-запрса с параметром 'analyseTEXT'. Вернёт .json-файл, с названиями категорий и вероятностью, с которой текст относится к каждой из них. В случае неправильного обращения(некорректного имени параметра), будет возвращён пустой json.
```
@application.route('/predictByText', methods=['POST'])
def classify_text():  # put application's code here
    data = request.form
    if data:
        data = data['analyseTEXT']
        if data:
            values = mp.predict_text()
            return jsonify(values)
        if data:
            return jsonify({})    
    else:
        return jsonify({}))
```

Пример такого.json-файла. Для статьи про [новый супергеройский фильм](https://russian.rt.com/nopolitics/article/924183-vechnye-film-marvel)

```
{
"Без политики": 50.7047,
"Бывший СССР": 0.0,
"Мероприятия RT" 0.0,
"Мир": 0.0,
"Наука": 49.2952,
"Новости партнёров": 0.0,
"Пресс-релизы": 0.0,
"Россия": 0.0,
"Спорт": 0.0,
"Экономика": 0.0 %
}
```

## Модель
Перед началом обучения, необходимо "очистить данные". В данном случае, все новые абзаци обозначаются латинской "n" после знака окончания предложения, а также между двумя "n", заключаются цитаты.
Для очищения обучающих данных использовали 2 регулярных выражения.

```(python)
regex_cite = re.compile(r'[n](?P<word>[^n]+)[n]')
regex_par = re.compile(r'(?P<sign>[.;])[n](?P<word>[\S]+)')
for i in range(len(texts)):
  texts[i] = re.sub(regex_cite, r' \g<word> ', re.sub(regex_par, r'\g<sign> \g<word> ', texts[i]))
```

Для представления слов в удобной для нейросети форме, используется класс из пакета препроцессинга keras.

```(python)
from tensorflow.keras.preprocessing.text import Tokenizer
tokenizer = Tokenizer(num_words=maxWordsCount, filters='«»!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n', lower=True, split=' ', oov_token='unknown', char_level=False)
```

Каждому слову присвается его уникальный номер.

```(python)
tokenizer.fit_on_texts(texts)
```

Используется полносвязная модель. 

```(python)
modelE = Sequential()
```

Процесс обучения модели.

```(python)
Epoch 1/10
1699/1699 [==============================] - 196s 113ms/step - loss: 0.4772 - accuracy: 0.8589 - val_loss: 0.1426 - val_accuracy: 0.9581
Epoch 2/10
1699/1699 [==============================] - 194s 114ms/step - loss: 0.0369 - accuracy: 0.9899 - val_loss: 0.1419 - val_accuracy: 0.9666
Epoch 3/10
1699/1699 [==============================] - 193s 113ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.2275 - val_accuracy: 0.9540
Epoch 4/10
1699/1699 [==============================] - 194s 114ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.2066 - val_accuracy: 0.9576
Epoch 5/10
1699/1699 [==============================] - 193s 113ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.2059 - val_accuracy: 0.9691
Epoch 6/10
1699/1699 [==============================] - 194s 114ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.2400 - val_accuracy: 0.9651
Epoch 7/10
1699/1699 [==============================] - 193s 113ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.1790 - val_accuracy: 0.9670
Epoch 8/10
1699/1699 [==============================] - 194s 114ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.2037 - val_accuracy: 0.9677
Epoch 9/10
1699/1699 [==============================] - 194s 114ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.1964 - val_accuracy: 0.9693
Epoch 10/10
1699/1699 [==============================] - 194s 114ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.2094 - val_accuracy: 0.9687
```

![graph](https://user-images.githubusercontent.com/47248368/141210154-684d5dda-d5fd-4700-88a3-98089de2471b.png)

Параметры полученной нейросети.

```(python)
modelE.summary()

Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_5 (Embedding)      (None, 500, 200)          20000000  
_________________________________________________________________
spatial_dropout1d_1 (Spatial (None, 500, 200)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 100000)            0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 100000)            400000    
_________________________________________________________________
dense_1 (Dense)              (None, 1000)              100001000 
_________________________________________________________________
dropout (Dropout)            (None, 1000)              0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 1000)              4000      
_________________________________________________________________
dense_2 (Dense)              (None, 10)                10010     
=================================================================
Total params: 120,415,010
Trainable params: 120,213,010
Non-trainable params: 202,000
_________________________________________________________________
```

### Результаты тестов

Для каждой категории была сформирована валидационная выборка. Затем, модель определяла её категорию, после вычислялись частоты правильного предсказания для текстов из каждой категории. 

```
Статистика: 
Тему: Без политики верно предсказывали в  99.326 % случаев
Тему: Бывший СССР верно предсказывали в  99.208 % случаев
Тему: Мероприятия RT верно предсказывали в  100.0 % случаев
Тему: Мир верно предсказывали в  99.3 % случаев
Тему: Наука верно предсказывали в  97.0 % случаев
Тему: Новости партнёров верно предсказывали в  100.0 % случаев
Тему: Пресс-релизы верно предсказывали в  100.0 % случаев
Тему: Россия верно предсказывали в  98.997 % случаев
Тему: Спорт верно предсказывали в  99.943 % случаев
Тему: Экономика верно предсказывали в  97.491 % случаев
Средняя точность составила:  99.1265 %
```
